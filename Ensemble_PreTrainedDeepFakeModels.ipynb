{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUrkvJ+G65eid0sH9ATeIQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JashandeepKairway/Ensemble-PreTrainedDeepFakeModels/blob/main/Ensemble_PreTrainedDeepFakeModels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install transformers datasets evaluate -q\n",
        "!pip install timm -q  # For image models\n",
        "\n",
        "# Step 1: Imports\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
        "import evaluate\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "# Step 2: Load Dataset (You can replace this with your custom dataset path or URL)\n",
        "from torchvision.datasets.utils import download_and_extract_archive\n",
        "\n",
        "# Sample Deepfake Dataset (replace with actual)\n",
        "# Example: https://www.kaggle.com/datasets/xhlulu/140k-real-and-fake-faces\n",
        "# Simulating with ImageFolder format\n",
        "dataset_path = \"saakshigupta/deepfake_dataset_simple\"  # Upload your dataset here\n",
        "transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n",
        "dataset = ImageFolder(dataset_path, transform=transform)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Step 3: Pre-trained Model List (Use Hugging Face model names)\n",
        "model_names = [\n",
        "    \"nateraw/vit-age-classifier\",  # Example only; replace with actual deepfake models\n",
        "    \"facebook/deit-base-distilled-patch16-224\",\n",
        "    \"microsoft/swin-tiny-patch4-window7-224\"\n",
        "]\n",
        "\n",
        "# Step 4: Evaluation Function\n",
        "def evaluate_model(model_name):\n",
        "    processor = AutoImageProcessor.from_pretrained(model_name)\n",
        "    model = AutoModelForImageClassification.from_pretrained(model_name).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.eval()\n",
        "\n",
        "    y_true, y_pred = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in val_loader:\n",
        "            inputs = processor(images=imgs, return_tensors=\"pt\").to(model.device)\n",
        "            outputs = model(**inputs)\n",
        "            predictions = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
        "            y_pred.extend(predictions)\n",
        "            y_true.extend(labels.numpy())\n",
        "\n",
        "    # Compute metrics\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel() if cm.shape == (2, 2) else (0, 0, 0, 0)\n",
        "    sensitivity = tp / (tp + fn + 1e-8)\n",
        "    specificity = tn / (tn + fp + 1e-8)\n",
        "    precision = precision_score(y_true, y_pred, average='binary')\n",
        "    recall = recall_score(y_true, y_pred, average='binary')\n",
        "    f1 = f1_score(y_true, y_pred, average='binary')\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    return [sensitivity, specificity, precision, recall, f1, accuracy]\n",
        "\n",
        "# Step 5: Loop Over Models\n",
        "import pandas as pd\n",
        "\n",
        "results = []\n",
        "for model_name in model_names:\n",
        "    print(f\"Evaluating {model_name}...\")\n",
        "    metrics = evaluate_model(model_name)\n",
        "    results.append(metrics)\n",
        "\n",
        "# Step 6: Convert to DataFrame and Add Ensemble Row (majority voting not shown)\n",
        "df = pd.DataFrame(results, columns=[\"Sensitivity\", \"Specificity\", \"Precision\", \"Recall\", \"F1\", \"Accuracy\"])\n",
        "df.insert(0, \"Models\", [f\"M{i+1}\" for i in range(len(results))])\n",
        "ensemble_row = [\"Ensemble\"] + list(np.mean(df.iloc[:, 1:], axis=0))  # simple average\n",
        "df.loc[len(df)] = ensemble_row\n",
        "\n",
        "# Step 7: Display Table\n",
        "from IPython.display import display\n",
        "display(df)\n"
      ],
      "metadata": {
        "id": "T4yd2XUW-HFi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}